flowchart TB
  %% =========================
  %% Back-Hackathon2025
  %% =========================
  subgraph Repo["Back-Hackathon2025"]
    mainpy["main.py\nDesktop bootstrap + env load"]
    agents["AGENTS.md"]
    session["SESSION.md"]
    pyproj["pyproject.toml\nPython deps"]
    projguide["project_structure_guide.txt"]
    envdir["env/"]
    scripts["scripts/"]
    utils["utils/"]
    builddist["build/ + dist/"]
    egg["back_hackathon2025.egg-info/"]
    vend["hand-gesture-recognition-mediapipe/\nreference repo"]
  end

  %% =========================
  %% Desktop
  %% =========================
  subgraph Desktop["Desktop App"]
    subgraph WebUI["webui (Tauri + React)"]
      react["React UI\nVite + Tailwind\nwebui/src"]
      tauri["Tauri Shell (Rust)\nspawns backend\nwebui/src-tauri"]
      tauriConf["tauri.conf.json"]
      pkg["package.json"]
      rsMain["main.rs"]
      rsLib["lib.rs"]
    end

    subgraph AltUI["ui (legacy)"]
      uinote["Alt/experimental UI"]
    end
  end

  %% =========================
  %% Backend
  %% =========================
  subgraph Backend["Python Backend"]
    apiSrv["api/server.py\nFastAPI + Uvicorn"]
    config["config/\nsettings + defaults"]
    dataDir["data/\npresets + resources"]
    userData["user_data/\nper-user datasets/models"]
  end

  %% =========================
  %% Gesture Pipeline
  %% =========================
  subgraph Gesture["Gesture Pipeline"]
    wf["GestureWorkflow\n(gesture_module/workflow.py)\ncollect/start/stop"]
    recog["Realtime Recognizer\n(gesture_module/gesture_recognizer.py)\nCamera -> MediaPipe -> TFLite"]
    tfl["Preprocess\n(video_module/tflite_pipeline.py)"]
    tflcls["TFLite Inference\n(video_module/tflite_classifiers.py)"]
    gml["Dataset utils\n(video_module/gesture_ml.py)"]
    cam["Webcam"]
    mp["MediaPipe Hands"]
    tflite[".tflite models"]
  end

  %% =========================
  %% Voice Pipeline
  %% =========================
  subgraph Voice["Voice Pipeline (optional)"]
    vlisten["VoiceListener\n(voice_module/voice_listener.py)\nmic stream"]
    stt["STT Engine\n(voice_module/stt_engine.py)\nLocal Whisper only"]
    mic["Microphone"]
    transcript["Transcript text"]
  end

  %% =========================
  %% Command System
  %% =========================
  subgraph Commands["Command System"]
    cc["CommandController\n(command_controller/controller.py)"]
    eng["CommandEngine\n(command_controller/engine.py)\nconfirmations queue"]
    llm["LLM Intent Parser\n(command_controller/llm.py)\nOllama local"]
    execu["Executor\n(command_controller/executor.py)\nPyAutoGUI"]
    pending["Pending confirmations\n/API polled by UI/"]
    os["Operating System"]
  end

  %% =========================
  %% Wiring
  %% =========================
  mainpy --> WebUI
  react <--> tauri
  tauri --> apiSrv
  react <--> apiSrv

  apiSrv --> wf
  apiSrv <--> config
  apiSrv <--> dataDir
  apiSrv <--> userData

  cam --> recog
  recog --> mp
  recog --> tfl
  recog --> tflcls
  tflcls --> tflite
  wf <--> gml
  wf <--> userData
  wf --> recog
  recog --> cc

  mic --> vlisten
  vlisten --> stt
  stt --> transcript
  transcript --> cc

  cc --> eng
  eng --> llm
  llm --> eng
  eng --> execu
  execu --> os

  eng --> pending
  pending --> apiSrv
  apiSrv --> react

  %% =========================
  %% Metadata links
  %% =========================
  pkg --- react
  tauriConf --- tauri
  rsMain --- tauri
  rsLib --- tauri
  projguide --- Repo
  agents --- Repo
  session --- Repo
  vend -. reference .- Gesture
